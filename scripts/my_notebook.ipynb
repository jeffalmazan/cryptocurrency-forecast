{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parquet():\n",
    "    cwd = os.getcwd()\n",
    "    print( \"Current Path:\", cwd )\n",
    "    os.chdir('../data')\n",
    "    data_dir = Path(os.getcwd() +'/parquet/')\n",
    "\n",
    "    # 2023 trip data dataframe\n",
    "    tripdata_2023_df = pd.concat(\n",
    "        pd.read_parquet(parquet_file)\n",
    "        for parquet_file in data_dir.glob('*.parquet')\n",
    "    )\n",
    "\n",
    "    return tripdata_2023_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cleanup(df):\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_timeseries_forecasting(df):\n",
    "    # Preprocess the data\n",
    "    df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "    df.set_index('tpep_pickup_datetime', inplace=True)\n",
    "\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    print(numeric_columns)\n",
    "    df[numeric_columns] = df[numeric_columns].resample('1H').mean().fillna(0)\n",
    "    \n",
    "    #df = df.resample('1H').mean().fillna(0)  # Resample to hourly and fill NaN values\n",
    "\n",
    "    # Splitting data into train and test sets\n",
    "    train_data, test_data = train_test_split(df, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # Define SARIMA parameters\n",
    "    #order = (2, 1, 1)  # ARIMA(p, d, q)\n",
    "    #seasonal_order = (1, 0, 1, 24)  # SARIMA(P, D, Q, m)\n",
    "    order = (1, 1, 1)  # ARIMA(p, d, q)\n",
    "    seasonal_order = (0, 1, 1, 12)  # SARIMA(P, D, Q, m)\n",
    "\n",
    "\n",
    "    # Fit SARIMA model\n",
    "    sarima_model = SARIMAX(train_data['fare_amount'], order=order, seasonal_order=seasonal_order, enforce_stationarity=False, enforce_invertibility=False)\n",
    "    sarima_result = sarima_model.fit()\n",
    "    sarima_result\n",
    "\n",
    "    # Make predictions\n",
    "    predicted = sarima_result.predict(start=test_data.index[0], end=test_data.index[-1], dynamic=True)\n",
    "    predicted\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(test_data['fare_amount'], predicted)\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "    # Plot actual vs. predicted fares\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(test_data.index, test_data['fare_amount'], label='Actual')\n",
    "    plt.plot(test_data.index, predicted, label='Predicted', color='red')\n",
    "    plt.title('Actual vs. Predicted Fare Amount (SARIMA)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Fare Amount')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Get parquet\n",
    "    print(\"#1 Read parquet\")\n",
    "    taxi_df = get_parquet()\n",
    "    print(taxi_df.info())\n",
    "\n",
    "    # Perform cleanup\n",
    "    print(\"#2 Perform cleanup\")\n",
    "    cleaned_df = perform_cleanup(taxi_df)\n",
    "\n",
    "    # Perform time series forecasting\n",
    "    #print(\"#3 Perform time series forecasting\")\n",
    "    #perform_timeseries_forecasting(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 Read parquet\n",
      "Current Path: C:\\Users\\denni\\Documents\\Lambton\\2nd term\\BDM 3014 - Introduction to AI\\project\\nyc-taxi-fare-prediction\\scripts\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 38310226 entries, 0 to 3376566\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   VendorID               int64         \n",
      " 1   tpep_pickup_datetime   datetime64[us]\n",
      " 2   tpep_dropoff_datetime  datetime64[us]\n",
      " 3   passenger_count        float64       \n",
      " 4   trip_distance          float64       \n",
      " 5   RatecodeID             float64       \n",
      " 6   store_and_fwd_flag     object        \n",
      " 7   PULocationID           int64         \n",
      " 8   DOLocationID           int64         \n",
      " 9   payment_type           int64         \n",
      " 10  fare_amount            float64       \n",
      " 11  extra                  float64       \n",
      " 12  mta_tax                float64       \n",
      " 13  tip_amount             float64       \n",
      " 14  tolls_amount           float64       \n",
      " 15  improvement_surcharge  float64       \n",
      " 16  total_amount           float64       \n",
      " 17  congestion_surcharge   float64       \n",
      " 18  airport_fee            float64       \n",
      " 19  Airport_fee            float64       \n",
      "dtypes: datetime64[us](2), float64(13), int64(4), object(1)\n",
      "memory usage: 6.0+ GB\n",
      "None\n",
      "#2 Perform cleanup\n",
      "VendorID                        0\n",
      "tpep_pickup_datetime            0\n",
      "tpep_dropoff_datetime           0\n",
      "passenger_count           1309356\n",
      "trip_distance                   0\n",
      "RatecodeID                1309356\n",
      "store_and_fwd_flag        1309356\n",
      "PULocationID                    0\n",
      "DOLocationID                    0\n",
      "payment_type                    0\n",
      "fare_amount                     0\n",
      "extra                           0\n",
      "mta_tax                         0\n",
      "tip_amount                      0\n",
      "tolls_amount                    0\n",
      "improvement_surcharge           0\n",
      "total_amount                    0\n",
      "congestion_surcharge      1309356\n",
      "airport_fee              35315203\n",
      "Airport_fee               4304379\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Path: C:\\Users\\denni\\Documents\\Lambton\\2nd term\\BDM 3014 - Introduction to AI\\project\\nyc-taxi-fare-prediction\\scripts\n"
     ]
    }
   ],
   "source": [
    " taxi_df = get_parquet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:32:10</td>\n",
       "      <td>2023-01-01 00:40:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>9.30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:55:08</td>\n",
       "      <td>2023-01-01 01:01:27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>43</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>7.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:25:04</td>\n",
       "      <td>2023-01-01 00:37:49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>48</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>14.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-01 00:03:48</td>\n",
       "      <td>2023-01-01 00:13:25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>12.10</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:10:29</td>\n",
       "      <td>2023-01-01 00:21:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>107</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>11.40</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.68</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066761</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-31 23:58:34</td>\n",
       "      <td>2023-02-01 00:12:33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>107</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>15.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066762</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-31 23:31:09</td>\n",
       "      <td>2023-01-31 23:50:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>112</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>22.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066763</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-31 23:01:05</td>\n",
       "      <td>2023-01-31 23:25:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>114</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>17.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066764</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-31 23:40:00</td>\n",
       "      <td>2023-01-31 23:53:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>230</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>18.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066765</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-31 23:07:32</td>\n",
       "      <td>2023-01-31 23:21:56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>262</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>15.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3066766 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0               2  2023-01-01 00:32:10   2023-01-01 00:40:36              1.0   \n",
       "1               2  2023-01-01 00:55:08   2023-01-01 01:01:27              1.0   \n",
       "2               2  2023-01-01 00:25:04   2023-01-01 00:37:49              1.0   \n",
       "3               1  2023-01-01 00:03:48   2023-01-01 00:13:25              0.0   \n",
       "4               2  2023-01-01 00:10:29   2023-01-01 00:21:19              1.0   \n",
       "...           ...                  ...                   ...              ...   \n",
       "3066761         2  2023-01-31 23:58:34   2023-02-01 00:12:33              NaN   \n",
       "3066762         2  2023-01-31 23:31:09   2023-01-31 23:50:36              NaN   \n",
       "3066763         2  2023-01-31 23:01:05   2023-01-31 23:25:36              NaN   \n",
       "3066764         2  2023-01-31 23:40:00   2023-01-31 23:53:00              NaN   \n",
       "3066765         2  2023-01-31 23:07:32   2023-01-31 23:21:56              NaN   \n",
       "\n",
       "         trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
       "0                 0.97         1.0                  N           161   \n",
       "1                 1.10         1.0                  N            43   \n",
       "2                 2.51         1.0                  N            48   \n",
       "3                 1.90         1.0                  N           138   \n",
       "4                 1.43         1.0                  N           107   \n",
       "...                ...         ...                ...           ...   \n",
       "3066761           3.05         NaN               None           107   \n",
       "3066762           5.80         NaN               None           112   \n",
       "3066763           4.67         NaN               None           114   \n",
       "3066764           3.15         NaN               None           230   \n",
       "3066765           2.85         NaN               None           262   \n",
       "\n",
       "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "0                 141             2         9.30   1.00      0.5        0.00   \n",
       "1                 237             1         7.90   1.00      0.5        4.00   \n",
       "2                 238             1        14.90   1.00      0.5       15.00   \n",
       "3                   7             1        12.10   7.25      0.5        0.00   \n",
       "4                  79             1        11.40   1.00      0.5        3.28   \n",
       "...               ...           ...          ...    ...      ...         ...   \n",
       "3066761            48             0        15.80   0.00      0.5        3.96   \n",
       "3066762            75             0        22.43   0.00      0.5        2.64   \n",
       "3066763           239             0        17.61   0.00      0.5        5.32   \n",
       "3066764            79             0        18.15   0.00      0.5        4.43   \n",
       "3066765           143             0        15.97   0.00      0.5        2.00   \n",
       "\n",
       "         tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0                 0.0                    1.0         14.30   \n",
       "1                 0.0                    1.0         16.90   \n",
       "2                 0.0                    1.0         34.90   \n",
       "3                 0.0                    1.0         20.85   \n",
       "4                 0.0                    1.0         19.68   \n",
       "...               ...                    ...           ...   \n",
       "3066761           0.0                    1.0         23.76   \n",
       "3066762           0.0                    1.0         29.07   \n",
       "3066763           0.0                    1.0         26.93   \n",
       "3066764           0.0                    1.0         26.58   \n",
       "3066765           0.0                    1.0         21.97   \n",
       "\n",
       "         congestion_surcharge  airport_fee  \n",
       "0                         2.5         0.00  \n",
       "1                         2.5         0.00  \n",
       "2                         2.5         0.00  \n",
       "3                         0.0         1.25  \n",
       "4                         2.5         0.00  \n",
       "...                       ...          ...  \n",
       "3066761                   NaN          NaN  \n",
       "3066762                   NaN          NaN  \n",
       "3066763                   NaN          NaN  \n",
       "3066764                   NaN          NaN  \n",
       "3066765                   NaN          NaN  \n",
       "\n",
       "[3066766 rows x 19 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perform_cleanup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m new_df \u001b[38;5;241m=\u001b[39m \u001b[43mperform_cleanup\u001b[49m(taxi_df)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#new_df['fare_amount_numeric'] = pd.to_numeric(new_df['fare_amount'], errors='coerce')\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#filtered_df = new_df[new_df['fare_amount_numeric'].isna()]\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#filtered_df\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#print(new_df['tpep_pickup_datetime'].dtype) \u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'perform_cleanup' is not defined"
     ]
    }
   ],
   "source": [
    "new_df = perform_cleanup(taxi_df)\n",
    "#new_df['fare_amount_numeric'] = pd.to_numeric(new_df['fare_amount'], errors='coerce')\n",
    "\n",
    "#filtered_df = new_df[new_df['fare_amount_numeric'].isna()]\n",
    "#filtered_df\n",
    "\n",
    "#print(new_df['tpep_pickup_datetime'].dtype) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['VendorID', 'passenger_count', 'trip_distance', 'RatecodeID',\n",
      "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
      "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
      "       'total_amount', 'congestion_surcharge', 'airport_fee'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\work\\TOOLS\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "D:\\work\\TOOLS\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "D:\\work\\TOOLS\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "D:\\work\\TOOLS\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "D:\\work\\TOOLS\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "D:\\work\\TOOLS\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for seasonal ARMA. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "D:\\work\\TOOLS\\Python311\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 13.3 GiB for an array with shape (27, 27, 2453413) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#taxi_df = get_parquet()\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mperform_timeseries_forecasting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtaxi_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 24\u001b[0m, in \u001b[0;36mperform_timeseries_forecasting\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Fit SARIMA model\u001b[39;00m\n\u001b[0;32m     23\u001b[0m sarima_model \u001b[38;5;241m=\u001b[39m SARIMAX(train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfare_amount\u001b[39m\u001b[38;5;124m'\u001b[39m], order\u001b[38;5;241m=\u001b[39morder, seasonal_order\u001b[38;5;241m=\u001b[39mseasonal_order, enforce_stationarity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, enforce_invertibility\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 24\u001b[0m sarima_result \u001b[38;5;241m=\u001b[39m \u001b[43msarima_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m sarima_result\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n",
      "File \u001b[1;32mD:\\work\\TOOLS\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:728\u001b[0m, in \u001b[0;36mMLEModel.fit\u001b[1;34m(self, start_params, transformed, includes_fixed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, low_memory, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    727\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth\n\u001b[1;32m--> 728\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlefit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincludes_fixed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m           \u001b[49m\u001b[43mcov_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov_kwds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov_kwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    731\u001b[0m res\u001b[38;5;241m.\u001b[39mmlefit \u001b[38;5;241m=\u001b[39m mlefit\n\u001b[0;32m    732\u001b[0m res\u001b[38;5;241m.\u001b[39mmle_retvals \u001b[38;5;241m=\u001b[39m mlefit\u001b[38;5;241m.\u001b[39mmle_retvals\n",
      "File \u001b[1;32mD:\\work\\TOOLS\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:886\u001b[0m, in \u001b[0;36mMLEModel.smooth\u001b[1;34m(self, params, transformed, includes_fixed, complex_step, cov_type, cov_kwds, return_ssm, results_class, results_wrapper_class, **kwargs)\u001b[0m\n\u001b[0;32m    883\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minversion_method\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m INVERT_UNIVARIATE \u001b[38;5;241m|\u001b[39m SOLVE_LU\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Get the state space output\u001b[39;00m\n\u001b[1;32m--> 886\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmooth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomplex_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomplex_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;66;03m# Wrap in a results object\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_results(params, result, return_ssm, cov_type,\n\u001b[0;32m    890\u001b[0m                           cov_kwds, results_class,\n\u001b[0;32m    891\u001b[0m                           results_wrapper_class)\n",
      "File \u001b[1;32mD:\\work\\TOOLS\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_smoother.py:403\u001b[0m, in \u001b[0;36mKalmanSmoother.smooth\u001b[1;34m(self, smoother_output, smooth_method, results, run_filter, prefix, complex_step, update_representation, update_filter, update_smoother, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;124;03mApply the Kalman smoother to the statespace model.\u001b[39;00m\n\u001b[0;32m    379\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;124;03mSmootherResults object\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;66;03m# Run the filter\u001b[39;00m\n\u001b[1;32m--> 403\u001b[0m kfilter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;66;03m# Create the results object\u001b[39;00m\n\u001b[0;32m    406\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults_class(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mD:\\work\\TOOLS\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:913\u001b[0m, in \u001b[0;36mKalmanFilter._filter\u001b[1;34m(self, filter_method, inversion_method, stability_method, conserve_memory, filter_timing, tolerance, loglikelihood_burn, complex_step)\u001b[0m\n\u001b[0;32m    907\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_filter\u001b[39m(\u001b[38;5;28mself\u001b[39m, filter_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inversion_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    908\u001b[0m             stability_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, conserve_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    909\u001b[0m             filter_timing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, loglikelihood_burn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    910\u001b[0m             complex_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    911\u001b[0m     \u001b[38;5;66;03m# Initialize the filter\u001b[39;00m\n\u001b[0;32m    912\u001b[0m     prefix, dtype, create_filter, create_statespace \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 913\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_filter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    914\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilter_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minversion_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstability_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconserve_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_timing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloglikelihood_burn\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m     )\n\u001b[0;32m    918\u001b[0m     kfilter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kalman_filters[prefix]\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;66;03m# Initialize the state\u001b[39;00m\n",
      "File \u001b[1;32mD:\\work\\TOOLS\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:501\u001b[0m, in \u001b[0;36mKalmanFilter._initialize_filter\u001b[1;34m(self, filter_method, inversion_method, stability_method, conserve_memory, tolerance, filter_timing, loglikelihood_burn)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;66;03m# Setup the filter\u001b[39;00m\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefix_kalman_filter_map[prefix]\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kalman_filters[prefix] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statespaces\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minversion_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstability_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconserve_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_timing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloglikelihood_burn\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# Otherwise, update the filter parameters\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     kalman_filter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kalman_filters[prefix]\n",
      "File \u001b[1;32mstatsmodels\\tsa\\statespace\\_kalman_filter.pyx:1720\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._kalman_filter.dKalmanFilter.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstatsmodels\\tsa\\statespace\\_kalman_filter.pyx:2131\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._kalman_filter.dKalmanFilter.set_filter_method\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstatsmodels\\tsa\\statespace\\_kalman_filter.pyx:1911\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._kalman_filter.dKalmanFilter.allocate_arrays\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 13.3 GiB for an array with shape (27, 27, 2453413) and data type float64"
     ]
    }
   ],
   "source": [
    "#taxi_df = get_parquet()\n",
    "perform_timeseries_forecasting(taxi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2023-01-01 00:32:10\n",
       "1         2023-01-01 00:55:08\n",
       "2         2023-01-01 00:25:04\n",
       "3         2023-01-01 00:03:48\n",
       "4         2023-01-01 00:10:29\n",
       "                  ...        \n",
       "3403761   2023-03-31 23:24:25\n",
       "3403762   2023-03-31 23:24:50\n",
       "3403763   2023-03-31 23:26:31\n",
       "3403764   2023-03-31 23:07:51\n",
       "3403765   2023-03-31 23:26:12\n",
       "Name: tpep_pickup_datetime, Length: 9384487, dtype: datetime64[us]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new_df['tpep_pickup_datetime'].dtype\n",
    "#taxi_df[taxi_df['fare_amount']=='NNNNN']\n",
    "#taxi_df\n",
    "taxi_df['tpep_pickup_datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column \"store_and_fwd_flag\" contains non-numeric values:\n",
      "0             N\n",
      "1             N\n",
      "2             N\n",
      "3             N\n",
      "4             N\n",
      "           ... \n",
      "3376562    None\n",
      "3376563    None\n",
      "3376564    None\n",
      "3376565    None\n",
      "3376566    None\n",
      "Name: store_and_fwd_flag, Length: 38310226, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Check data types of columns\n",
    "column_data_types = taxi_df.dtypes\n",
    "\n",
    "# Filter columns with non-numeric data types (e.g., object, string)\n",
    "non_numeric_columns = column_data_types[column_data_types == 'object'].index\n",
    "\n",
    "# Check for non-numeric values in non-numeric columns\n",
    "for col in non_numeric_columns:\n",
    "    non_numeric_values = taxi_df[col].loc[~pd.to_numeric(taxi_df[col], errors='coerce').notna()]\n",
    "    if not non_numeric_values.empty:\n",
    "        print(f'Column \"{col}\" contains non-numeric values:')\n",
    "        print(non_numeric_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
